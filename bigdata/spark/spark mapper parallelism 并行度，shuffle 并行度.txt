In order to control specific partitioning of an RDD you can use "repartition" method or "coalesce" method. If you want to be have it on all rdds for all mappers you should use: sparkConf.set("spark.default.parallelism", s"${numbers of mappers you want}") If you want to controll the shuffle (reducers) sparkConf.set("spark.sql.shuffle.partitions", s"${numbers of reducers you want}")